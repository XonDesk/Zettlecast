# Zettlecast Configuration
# Copy this to .env and customize

# --- API Security ---
# Auto-generated on first run if not set
# API_TOKEN=your_secure_token_here

# --- Storage Paths ---
STORAGE_PATH=~/_BRAIN_STORAGE
LANCEDB_PATH=~/_BRAIN_STORAGE/.lancedb

# --- Embedding Model ---
# google/embeddinggemma-300m (high quality, 300M params)
# sentence-transformers/all-MiniLM-L6-v2 (lite fallback)
EMBEDDING_MODEL=google/embeddinggemma-300m

# --- Reranker ---
RERANKER_MODEL=BAAI/bge-reranker-v2-m3

# --- Audio Transcription ---
# ASR Backend: auto, nemo, parakeet-mlx, whisper
# - auto: Selects best backend for your platform
# - nemo: NeMo Parakeet-TDT (Windows GPU, runs in Docker)
# - parakeet-mlx: Apple MLX optimized (Mac M-series)
# - whisper: faster-whisper fallback (any platform)
ASR_BACKEND=auto

# Diarization: auto, pyannote, nemo, none
# - auto: pyannote on Mac, NeMo MSDD on Windows
# - pyannote: pyannote.audio 3.1 (requires HF_TOKEN)
# - nemo: NeMo TitaNet + MSDD (Windows container)
# - none: Disable speaker diarization
DIARIZATION_BACKEND=auto

# Device: auto, cpu, cuda, mps
WHISPER_DEVICE=auto

# Whisper model (used as fallback): large-v3-turbo, distil-large-v3
WHISPER_MODEL=large-v3-turbo

# Mac: parakeet-mlx model
PARAKEET_MODEL=mlx-community/parakeet-tdt-0.6b-v3

# Windows: NeMo container settings
NEMO_CONTAINER_IMAGE=zettlecast/nemo-asr:latest
NEMO_CONTAINER_AUTO_START=true

# HuggingFace token (required for pyannote diarization)
# Get your token at: https://huggingface.co/settings/tokens
# Must accept license at: https://huggingface.co/pyannote/speaker-diarization-3.1
HF_TOKEN=

# --- LLM Provider ---
# Options: ollama, openai, anthropic
LLM_PROVIDER=ollama
OLLAMA_MODEL=llama3.2:3b
OLLAMA_BASE_URL=http://localhost:11434

# For cloud LLM (if LLM_PROVIDER=openai or anthropic)
# OPENAI_API_KEY=sk-...
# ANTHROPIC_API_KEY=sk-ant-...

# --- Features ---
# Context enrichment adds LLM-generated summaries to chunks (slow)
ENABLE_CONTEXT_ENRICHMENT=false
# How long to cache link suggestions (hours)
SUGGESTION_CACHE_HOURS=24
# Max file size to process (MB)
MAX_FILE_SIZE_MB=50

# --- Chunking ---
CHUNK_SIZE=512
CHUNK_OVERLAP=50

# --- Server ---
API_PORT=8000
UI_PORT=8501
